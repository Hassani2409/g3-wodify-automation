# ü§ñ LLM-Integration Setup - Echte Gespr√§che f√ºhren

## √úbersicht

Um echte, intelligente Gespr√§che mit dem Phone Assistant und Chatbot zu f√ºhren, k√∂nnen Sie eine LLM-Integration einrichten. Das System unterst√ºtzt:

- **OpenAI** (GPT-4, GPT-4o-mini, etc.)
- **Anthropic Claude** (Claude 3 Haiku, Sonnet, etc.)
- **Fallback** (Regelbasierte Antworten, wenn kein LLM konfiguriert ist)

---

## üöÄ Schnellstart mit OpenAI

### Schritt 1: OpenAI API Key erhalten

1. Gehen Sie zu [OpenAI Platform](https://platform.openai.com/)
2. Erstellen Sie ein Konto oder melden Sie sich an
3. Gehen Sie zu **API Keys** ‚Üí **Create new secret key**
4. Kopieren Sie den API Key (beginnt mit `sk-...`)

### Schritt 2: Dependencies installieren

```bash
pip install openai
```

### Schritt 3: Environment-Variablen konfigurieren

F√ºgen Sie in Ihre `.env` Datei hinzu:

```env
# LLM Configuration
OPENAI_API_KEY=sk-your-api-key-here
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=500
```

### Schritt 4: Backend neu starten

```bash
python main.py
# oder
uvicorn main:app --reload
```

**Fertig!** üéâ Der Phone Assistant und Chatbot verwenden jetzt echte KI-Antworten.

---

## üéØ Alternative: Anthropic Claude

### Schritt 1: Anthropic API Key erhalten

1. Gehen Sie zu [Anthropic Console](https://console.anthropic.com/)
2. Erstellen Sie ein Konto
3. Gehen Sie zu **API Keys** ‚Üí **Create Key**
4. Kopieren Sie den API Key

### Schritt 2: Dependencies installieren

```bash
pip install anthropic
```

### Schritt 3: Environment-Variablen konfigurieren

```env
# LLM Configuration
ANTHROPIC_API_KEY=sk-ant-your-api-key-here
LLM_PROVIDER=anthropic
LLM_MODEL=claude-3-haiku-20240307
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=500
```

---

## ‚öôÔ∏è Konfigurationsoptionen

### LLM Provider

```env
LLM_PROVIDER=openai        # oder "anthropic" oder "fallback"
```

### Model-Auswahl

**OpenAI Models:**
- `gpt-4o-mini` - Schnell und g√ºnstig (empfohlen)
- `gpt-4o` - Besser, aber teurer
- `gpt-4-turbo` - Sehr gut, aber teuer
- `gpt-3.5-turbo` - Alt, aber g√ºnstig

**Anthropic Models:**
- `claude-3-haiku-20240307` - Schnell und g√ºnstig (empfohlen)
- `claude-3-sonnet-20240229` - Besser, aber teurer
- `claude-3-opus-20240229` - Beste Qualit√§t, aber teuer

### Temperature

```env
LLM_TEMPERATURE=0.7  # 0.0 = konservativ, 1.0 = kreativ
```

- **0.0-0.3**: Sehr konservativ, vorhersagbar
- **0.4-0.7**: Ausgewogen (empfohlen)
- **0.8-1.0**: Kreativ, variabel

### Max Tokens

```env
LLM_MAX_TOKENS=500  # Maximale Antwortl√§nge
```

- **200-300**: Sehr kurz
- **500**: Kurz bis mittel (empfohlen f√ºr Chat)
- **1000+**: L√§ngere Antworten

---

## üí∞ Kosten-√úbersicht

### OpenAI GPT-4o-mini (empfohlen)
- **Input**: $0.15 / 1M Tokens
- **Output**: $0.60 / 1M Tokens
- **Gesch√§tzte Kosten**: ~$0.001 pro Gespr√§ch (10 Nachrichten)

### Anthropic Claude 3 Haiku (empfohlen)
- **Input**: $0.25 / 1M Tokens
- **Output**: $1.25 / 1M Tokens
- **Gesch√§tzte Kosten**: ~$0.002 pro Gespr√§ch (10 Nachrichten)

### Fallback (kostenlos)
- Regelbasierte Antworten
- Keine API-Kosten
- Begrenzte Flexibilit√§t

---

## üîç Testen der Integration

### 1. Phone Assistant testen

1. √ñffnen Sie die Website
2. Klicken Sie auf den Phone-Button (unten links)
3. Klicken Sie auf "Anrufen"
4. Stellen Sie eine Frage, z.B.:
   - "Was kostet eine Mitgliedschaft?"
   - "Kann ich heute noch ein Probetraining buchen?"
   - "Erz√§hl mir mehr √ºber eure Kurse"

### 2. Chatbot testen

1. √ñffnen Sie die Website
2. Klicken Sie auf den Chat-Button (unten rechts)
3. Stellen Sie eine Frage

### 3. Backend-Logs pr√ºfen

```bash
# Sie sollten sehen:
INFO: Generating AI response for prompt: ...
INFO: Using LLM provider: openai
```

---

## üêõ Troubleshooting

### Problem: "OpenAI library not installed"

**L√∂sung:**
```bash
pip install openai
```

### Problem: "OpenAI API key not configured"

**L√∂sung:**
1. Pr√ºfen Sie, ob `OPENAI_API_KEY` in `.env` gesetzt ist
2. Backend neu starten
3. Pr√ºfen Sie die Logs: `LLM provider: openai`

### Problem: "API request failed"

**L√∂sung:**
1. Pr√ºfen Sie Ihre Internetverbindung
2. Pr√ºfen Sie, ob der API Key g√ºltig ist
3. Pr√ºfen Sie Ihr OpenAI/Anthropic Guthaben
4. System verwendet automatisch Fallback-Antworten

### Problem: Antworten sind zu lang/kurz

**L√∂sung:**
- `LLM_MAX_TOKENS` anpassen (z.B. 300 f√ºr k√ºrzer, 800 f√ºr l√§nger)
- `LLM_TEMPERATURE` anpassen (niedriger = konservativer)

---

## üìä Monitoring

### Logs pr√ºfen

```bash
# Backend-Logs zeigen:
- Welcher LLM-Provider verwendet wird
- API-Aufrufe und Fehler
- Fallback-Nutzung
```

### Kosten √ºberwachen

- **OpenAI**: [Usage Dashboard](https://platform.openai.com/usage)
- **Anthropic**: [Console Dashboard](https://console.anthropic.com/)

---

## üéØ Best Practices

1. **Start mit GPT-4o-mini**: Gute Balance zwischen Kosten und Qualit√§t
2. **Temperature 0.7**: Ausgewogen f√ºr Kundenservice
3. **Max Tokens 500**: Kurz genug f√ºr Chat, lang genug f√ºr Details
4. **Fallback aktiviert**: System funktioniert auch ohne LLM
5. **Monitoring**: √úberwachen Sie Kosten und Nutzung

---

## üîê Sicherheit

- **Niemals API Keys committen**: Verwenden Sie `.env` Dateien
- **API Keys rotieren**: Regelm√§√üig neue Keys erstellen
- **Rate Limiting**: Backend hat bereits Rate Limiting implementiert
- **Input Validation**: Alle Eingaben werden validiert

---

## ‚úÖ Checkliste

- [ ] OpenAI oder Anthropic Account erstellt
- [ ] API Key erhalten
- [ ] Dependencies installiert (`pip install openai` oder `pip install anthropic`)
- [ ] `.env` Datei konfiguriert
- [ ] Backend neu gestartet
- [ ] Phone Assistant getestet
- [ ] Chatbot getestet
- [ ] Logs gepr√ºft

---

## üöÄ N√§chste Schritte

Nach der Einrichtung k√∂nnen Sie:

1. **LangGraph integrieren** f√ºr komplexere Workflows
2. **Tool-Calling** f√ºr direkte Aktionen (Buchungen, etc.)
3. **Conversation History** im Backend speichern
4. **Analytics** f√ºr Gespr√§che hinzuf√ºgen

Viel Erfolg! üéâ

